{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dat_files/fraction_ML_0.5_cost.dat and dat_files/fraction_ML_0.5_time.dat\n",
      "Done generating .dat files by fraction.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "detailed_filename =  '/Users/ftb123/MLQCP_FM/benchmarking/JSON_data/benchmark_results_FM_CP_ML_0.5.json'\n",
    "output_dir = \"dat_files\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "with open(detailed_filename, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "\"\"\"\n",
    " data is a list of dicts, each with keys:\n",
    "  {\n",
    "    \"num_qubits\": int,\n",
    "    \"fraction\": float,\n",
    "    \"iteration\": int,\n",
    "    \"f_cost\": float,\n",
    "    \"w_cost\": float,\n",
    "    \"b_cost\": float,\n",
    "    \"r_cost\": float,\n",
    "    \"time_f\": float,\n",
    "    \"time_w\": float,\n",
    "    \"time_b\": float,\n",
    "    \"time_r\": float,\n",
    "    ...\n",
    "  }\n",
    "\"\"\"\n",
    "\n",
    "grouped = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "for entry in data:\n",
    "    frac = entry[\"fraction\"]\n",
    "    nq = entry[\"num_qubits\"]\n",
    "    grouped[frac][nq].append(entry)\n",
    "\n",
    "def compute_stats(values):\n",
    "    \"\"\"Return (mean, min, max) of a list of floats, safely as Python floats.\"\"\"\n",
    "    arr = np.array(values, dtype=float)\n",
    "    return float(np.mean(arr)), float(np.min(arr)), float(np.max(arr))\n",
    "\n",
    "for frac, frac_dict in grouped.items():\n",
    "    sorted_nq = sorted(frac_dict.keys())\n",
    "\n",
    "    cost_filename = os.path.join(output_dir, f\"fraction_ML_{frac}_cost.dat\")\n",
    "    time_filename = os.path.join(output_dir, f\"fraction_ML_{frac}_time.dat\")\n",
    "\n",
    "    with open(cost_filename, \"w\") as cf, open(time_filename, \"w\") as tf:\n",
    "\n",
    "        cf.write(\n",
    "            \"num_qubits\"\n",
    "            \" f_mean f_min f_max\"\n",
    "            \" w_mean w_min w_max\"\n",
    "            \" b_mean b_min b_max\"\n",
    "            \" r_mean r_min r_max\\n\"\n",
    "        )\n",
    "        tf.write(\n",
    "            \"num_qubits\"\n",
    "            \" f_mean f_min f_max\"\n",
    "            \" w_mean w_min w_max\"\n",
    "            \" b_mean b_min b_max\"\n",
    "            \" r_mean r_min r_max\\n\"\n",
    "        )\n",
    "\n",
    "        for nq in sorted_nq:\n",
    "            entries = frac_dict[nq]\n",
    "\n",
    "            # Gather lists for cost\n",
    "            f_costs = [e[\"f_cost\"] for e in entries]\n",
    "            w_costs = [e[\"w_cost\"] for e in entries]\n",
    "            b_costs = [e[\"b_cost\"] for e in entries]\n",
    "            r_costs = [e[\"r_cost\"] for e in entries]\n",
    "\n",
    "            # Gather lists for time\n",
    "            f_times = [e[\"time_f\"] for e in entries]\n",
    "            w_times = [e[\"time_w\"] for e in entries]\n",
    "            b_times = [e[\"time_b\"] for e in entries]\n",
    "            r_times = [e[\"time_r\"] for e in entries]\n",
    "\n",
    "            # Compute mean/min/max\n",
    "            f_cost_mean, f_cost_min, f_cost_max = compute_stats(f_costs)\n",
    "            w_cost_mean, w_cost_min, w_cost_max = compute_stats(w_costs)\n",
    "            b_cost_mean, b_cost_min, b_cost_max = compute_stats(b_costs)\n",
    "            r_cost_mean, r_cost_min, r_cost_max = compute_stats(r_costs)\n",
    "\n",
    "            f_time_mean, f_time_min, f_time_max = compute_stats(f_times)\n",
    "            w_time_mean, w_time_min, w_time_max = compute_stats(w_times)\n",
    "            b_time_mean, b_time_min, b_time_max = compute_stats(b_times)\n",
    "            r_time_mean, r_time_min, r_time_max = compute_stats(r_times)\n",
    "\n",
    "            # Write row for cost.dat\n",
    "            cf.write(\n",
    "                f\"{nq} \"\n",
    "                f\"{f_cost_mean} {f_cost_min} {f_cost_max} \"\n",
    "                f\"{w_cost_mean} {w_cost_min} {w_cost_max} \"\n",
    "                f\"{b_cost_mean} {b_cost_min} {b_cost_max} \"\n",
    "                f\"{r_cost_mean} {r_cost_min} {r_cost_max}\\n\"\n",
    "            )\n",
    "\n",
    "            # Write row for time.dat\n",
    "            tf.write(\n",
    "                f\"{nq} \"\n",
    "                f\"{f_time_mean} {f_time_min} {f_time_max} \"\n",
    "                f\"{w_time_mean} {w_time_min} {w_time_max} \"\n",
    "                f\"{b_time_mean} {b_time_min} {b_time_max} \"\n",
    "                f\"{r_time_mean} {r_time_min} {r_time_max}\\n\"\n",
    "            )\n",
    "\n",
    "    print(f\"Created {cost_filename} and {time_filename}\")\n",
    "\n",
    "print(\"Done generating .dat files by fraction.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dat_files/fraction_0.3_cost.dat and dat_files/fraction_0.3_time.dat\n",
      "Created dat_files/fraction_0.5_cost.dat and dat_files/fraction_0.5_time.dat\n",
      "Created dat_files/fraction_0.7_cost.dat and dat_files/fraction_0.7_time.dat\n",
      "Created dat_files/fraction_0.9_cost.dat and dat_files/fraction_0.9_time.dat\n",
      "Done generating .dat files by fraction.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "detailed_filename =  '/Users/ftb123/MLQCP_FM/benchmarking/benchmark_results_MLFM-R_CP_2-12_new.json'\n",
    "output_dir = \"dat_files\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "with open(detailed_filename, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "\"\"\"\n",
    " data is a list of dicts, each with keys:\n",
    "  {\n",
    "    \"num_qubits\": int,\n",
    "    \"fraction\": float,\n",
    "    \"iteration\": int,\n",
    "    \"r_cost\": float,\n",
    "    \"time_r\": float,\n",
    "    ...\n",
    "  }\n",
    "\"\"\"\n",
    "\n",
    "grouped = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "for entry in data:\n",
    "    frac = entry[\"fraction\"]\n",
    "    nq = entry[\"num_qubits\"]\n",
    "    grouped[frac][nq].append(entry)\n",
    "\n",
    "def compute_stats(values):\n",
    "    \"\"\"Return (mean, min, max) of a list of floats, safely as Python floats.\"\"\"\n",
    "    arr = np.array(values, dtype=float)\n",
    "    return float(np.mean(arr)), float(np.min(arr)), float(np.max(arr))\n",
    "\n",
    "for frac, frac_dict in grouped.items():\n",
    "    sorted_nq = sorted(frac_dict.keys())\n",
    "\n",
    "    cost_filename = os.path.join(output_dir, f\"fraction_{frac}_cost.dat\")\n",
    "    time_filename = os.path.join(output_dir, f\"fraction_{frac}_time.dat\")\n",
    "\n",
    "    with open(cost_filename, \"w\") as cf, open(time_filename, \"w\") as tf:\n",
    "\n",
    "        cf.write(\n",
    "            \"num_qubits\"\n",
    "            \" r_mean r_min r_max\\n\"\n",
    "        )\n",
    "        tf.write(\n",
    "            \"num_qubits\"\n",
    "            \" r_mean r_min r_max\\n\"\n",
    "        )\n",
    "\n",
    "        for nq in sorted_nq:\n",
    "            entries = frac_dict[nq]\n",
    "\n",
    "            # Gather lists for cost\n",
    "            r_costs = [e[\"r_cost\"] for e in entries]\n",
    "\n",
    "            # Gather lists for time\n",
    "            r_times = [e[\"time_r\"] for e in entries]\n",
    "\n",
    "            # Compute mean/min/max\n",
    "            r_cost_mean, r_cost_min, r_cost_max = compute_stats(r_costs)\n",
    "\n",
    "            r_time_mean, r_time_min, r_time_max = compute_stats(r_times)\n",
    "\n",
    "            # Write row for cost.dat\n",
    "            cf.write(\n",
    "                f\"{nq} \"\n",
    "                f\"{r_cost_mean} {r_cost_min} {r_cost_max}\\n\"\n",
    "            )\n",
    "\n",
    "            # Write row for time.dat\n",
    "            tf.write(\n",
    "                f\"{nq} \"\n",
    "                f\"{r_time_mean} {r_time_min} {r_time_max}\\n\"\n",
    "            )\n",
    "\n",
    "    print(f\"Created {cost_filename} and {time_filename}\")\n",
    "\n",
    "print(\"Done generating .dat files by fraction.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dat_files/CP_large_2_cost.dat and dat_files/CP_large_2_time.dat\n",
      "Created dat_files/CP_large_4_cost.dat and dat_files/CP_large_4_time.dat\n",
      "Done generating .dat files by fraction.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "detailed_filename =  '/Users/ftb123/MLQCP_FM/benchmarking/benchmark_results_MLFM-R_CP_large_2-4part_new.json'\n",
    "output_dir = \"dat_files\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "with open(detailed_filename, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "\"\"\"\n",
    " data is a list of dicts, each with keys:\n",
    "  {\n",
    "    \"num_qubits\": int,\n",
    "    \"fraction\": float,\n",
    "    \"iteration\": int,\n",
    "    \"r_cost\": float,\n",
    "    \"time_r\": float,\n",
    "    ...\n",
    "  }\n",
    "\"\"\"\n",
    "\n",
    "grouped = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "for entry in data:\n",
    "    num_partitions = entry[\"num_partitions\"]\n",
    "    nq = entry[\"num_qubits\"]\n",
    "    grouped[num_partitions][nq].append(entry)\n",
    "\n",
    "def compute_stats(values):\n",
    "    \"\"\"Return (mean, min, max) of a list of floats, safely as Python floats.\"\"\"\n",
    "    arr = np.array(values, dtype=float)\n",
    "    return float(np.mean(arr)), float(np.min(arr)), float(np.max(arr))\n",
    "\n",
    "for num_partitions, frac_dict in grouped.items():\n",
    "    sorted_nq = sorted(frac_dict.keys())\n",
    "\n",
    "    cost_filename = os.path.join(output_dir, f\"CP_large_{num_partitions}_cost.dat\")\n",
    "    time_filename = os.path.join(output_dir, f\"CP_large_{num_partitions}_time.dat\")\n",
    "\n",
    "    with open(cost_filename, \"w\") as cf, open(time_filename, \"w\") as tf:\n",
    "\n",
    "        cf.write(\n",
    "            \"num_qubits\"\n",
    "            \" r_mean r_min r_max\\n\"\n",
    "        )\n",
    "        tf.write(\n",
    "            \"num_qubits\"\n",
    "            \" r_mean r_min r_max\\n\"\n",
    "        )\n",
    "\n",
    "        for nq in sorted_nq:\n",
    "            entries = frac_dict[nq]\n",
    "\n",
    "            # Gather lists for cost\n",
    "            r_costs = [e[\"r_cost\"] for e in entries]\n",
    "\n",
    "            # Gather lists for time\n",
    "            r_times = [e[\"time_r\"] for e in entries]\n",
    "\n",
    "            # Compute mean/min/max\n",
    "            r_cost_mean, r_cost_min, r_cost_max = compute_stats(r_costs)\n",
    "\n",
    "            r_time_mean, r_time_min, r_time_max = compute_stats(r_times)\n",
    "\n",
    "            # Write row for cost.dat\n",
    "            cf.write(\n",
    "                f\"{nq} \"\n",
    "                f\"{r_cost_mean} {r_cost_min} {r_cost_max}\\n\"\n",
    "            )\n",
    "\n",
    "            # Write row for time.dat\n",
    "            tf.write(\n",
    "                f\"{nq} \"\n",
    "                f\"{r_time_mean} {r_time_min} {r_time_max}\\n\"\n",
    "            )\n",
    "\n",
    "    print(f\"Created {cost_filename} and {time_filename}\")\n",
    "\n",
    "print(\"Done generating .dat files by fraction.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dat_files/CP_net_coarse_256_cost_grid.dat and dat_files/CP_net_coarse_256_time_grid.dat\n",
      "Done generating .dat files by fraction.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "detailed_filename =  '/Users/ftb123/MLQCP_FM/benchmarking/benchmark_results_MLFM-R_QAOA_2-4part_new.json'\n",
    "\n",
    "output_dir = \"dat_files\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "with open(detailed_filename, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "\"\"\"\n",
    " data is a list of dicts, each with keys:\n",
    "  {\n",
    "    \"num_qubits\": int,\n",
    "    \"fraction\": float,\n",
    "    \"iteration\": int,\n",
    "    \"r_cost\": float,\n",
    "    \"time_r\": float,\n",
    "    ...\n",
    "  }\n",
    "\"\"\"\n",
    "\n",
    "grouped = defaultdict(list)\n",
    "for entry in data:\n",
    "    nq = entry[\"num_qubits\"]\n",
    "    grouped[nq].append(entry)\n",
    "\n",
    "\n",
    "def compute_stats(values):\n",
    "    \"\"\"Return (mean, min, max) of a list of floats, safely as Python floats.\"\"\"\n",
    "    arr = np.array(values, dtype=float)\n",
    "    return float(np.mean(arr)), float(np.min(arr)), float(np.max(arr))\n",
    "\n",
    "for nq, entries in grouped.items():\n",
    "    sorted_nq = sorted(grouped.keys())\n",
    "    # Prepare filenames\n",
    "    cost_filename = os.path.join(output_dir, f\"QV_2_cost.dat\")\n",
    "    time_filename = os.path.join(output_dir, f\"QV_2_time.dat\")\n",
    "\n",
    "with open(cost_filename, \"w\") as cf, open(time_filename, \"w\") as tf:\n",
    "    # Write headers\n",
    "    cf.write(\n",
    "        \"num_qubits\"\n",
    "        \" r_mean r_min r_max\\n\"\n",
    "    )\n",
    "    tf.write(\n",
    "        \"num_qubits\"\n",
    "        \" r_mean r_min r_max\\n\"\n",
    "    )\n",
    "\n",
    "    for nq in sorted_nq:\n",
    "        entries = grouped[nq]\n",
    "\n",
    "        # Gather lists for cost\n",
    "        r_costs = [e[\"r_cost\"] for e in entries]\n",
    "        # Gather lists for time\n",
    "        r_times = [e[\"time_r\"] for e in entries]\n",
    "\n",
    "        # Compute mean/min/max\n",
    "        r_cost_mean, r_cost_min, r_cost_max = compute_stats(r_costs)\n",
    "        r_time_mean, r_time_min, r_time_max = compute_stats(r_times)\n",
    "\n",
    "        cf.write(\n",
    "            f\"{nq} \"\n",
    "            f\"{r_cost_mean} {r_cost_min} {r_cost_max}\\n\"\n",
    "        )\n",
    "\n",
    "        # Write row for time.dat\n",
    "        tf.write(\n",
    "            f\"{nq} \"\n",
    "            f\"{r_time_mean} {r_time_min} {r_time_max}\\n\"\n",
    "        )\n",
    "\n",
    "print(f\"Created {cost_filename} and {time_filename}\")\n",
    "\n",
    "print(\"Done generating .dat files by fraction.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import statistics\n",
    "from collections import defaultdict\n",
    "import os\n",
    "\n",
    "def create_dat_file_from_json(input_json_path: str, output_dat_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Reads a JSON file containing dictionaries of the form:\n",
    "        {\n",
    "          \"num_qubits\": 16,\n",
    "          \"fraction\": 0.3,\n",
    "          \"r_cost\": 7,\n",
    "          \"time_r\": 0.049044132232666016,\n",
    "          \"ebit_fraction\": 0.16666666666666666,\n",
    "          ...\n",
    "        }\n",
    "    Groups by (num_qubits, fraction) and computes:\n",
    "        * mean(r_cost), mean(time_r), mean(ebit_fraction)\n",
    "        * lower and upper bound (mean ± std) for each.\n",
    "    Writes these statistics to a .dat file, sorted by fraction first,\n",
    "    and num_qubits second (both ascending).\n",
    "    \"\"\"\n",
    "    # 1. Read the JSON file\n",
    "    with open(input_json_path, 'r') as f:\n",
    "        data = json.load(f)  # Assumes the file is a JSON list of objects\n",
    "    if not os.path.exists(output_dat_path):\n",
    "        os.makedirs(output_dat_path)\n",
    "    # 2. Group the entries by (num_qubits, fraction)\n",
    "    grouped = defaultdict(list)\n",
    "    for entry in data:\n",
    "        key = (entry['num_qubits'], entry['fraction'])\n",
    "        grouped[key].append(entry)\n",
    "    \n",
    "    # 3. Compute statistics\n",
    "    results = []\n",
    "    for (num_qubits, fraction), items in grouped.items():\n",
    "        r_costs = [item['r_cost'] for item in items]\n",
    "        times = [item['time_r'] for item in items]\n",
    "        ebits = [item['ebit_fraction'] for item in items]\n",
    "        \n",
    "        # Mean\n",
    "        r_cost_mean = statistics.mean(r_costs)\n",
    "        time_mean = statistics.mean(times)\n",
    "        ebit_mean = statistics.mean(ebits)\n",
    "        \n",
    "        # Standard deviation (use 0 if only 1 item to avoid ValueError)\n",
    "        r_cost_std = statistics.stdev(r_costs) if len(r_costs) > 1 else 0\n",
    "        time_std = statistics.stdev(times) if len(times) > 1 else 0\n",
    "        ebit_std = statistics.stdev(ebits) if len(ebits) > 1 else 0\n",
    "        \n",
    "        # Lower and upper bounds\n",
    "        r_cost_lower, r_cost_upper = r_cost_mean - r_cost_std, r_cost_mean + r_cost_std\n",
    "        time_lower, time_upper = time_mean - time_std, time_mean + time_std\n",
    "        ebit_lower, ebit_upper = ebit_mean - ebit_std, ebit_mean + ebit_std\n",
    "        \n",
    "        results.append(\n",
    "            (\n",
    "                num_qubits, \n",
    "                fraction,\n",
    "                r_cost_mean, r_cost_lower, r_cost_upper,\n",
    "                time_mean, time_lower, time_upper,\n",
    "                ebit_mean, ebit_lower, ebit_upper\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    # 4. Sort the results:\n",
    "    #    * First by fraction ascending\n",
    "    #    * Then by num_qubits ascending\n",
    "    results.sort(key=lambda x: (x[1], x[0]))\n",
    "\n",
    "    # 5. Write statistics to a .dat file\n",
    "    filename = os.path.join(output_dat_path, \"Random_CP_2-12.dat\")\n",
    "    with open(filename, 'w') as out:\n",
    "        # Header\n",
    "        out.write(\"# num_qubits fraction r_cost_mean r_cost_lower r_cost_upper \"\n",
    "                  \"time_r_mean time_r_lower time_r_upper \"\n",
    "                  \"ebit_fraction_mean ebit_fraction_lower ebit_fraction_upper\\n\")\n",
    "        \n",
    "        for row in results:\n",
    "            (nq, frac, \n",
    "             rc_mean, rc_low, rc_up, \n",
    "             t_mean, t_low, t_up, \n",
    "             e_mean, e_low, e_up) = row\n",
    "            out.write(f\"{nq} {frac} \"\n",
    "                      f\"{rc_mean:.6f} {rc_low:.6f} {rc_up:.6f} \"\n",
    "                      f\"{t_mean:.6f} {t_low:.6f} {t_up:.6f} \"\n",
    "                      f\"{e_mean:.6f} {e_low:.6f} {e_up:.6f}\\n\")\n",
    "            \n",
    "\n",
    "def create_dat_file_from_json_tket(input_json_path: str, output_dat_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Reads a JSON file containing dictionaries of the form:\n",
    "        {\n",
    "          \"num_qubits\": 16,\n",
    "          \"fraction\": 0.3,\n",
    "          \"PE_cost\": 7,\n",
    "          \"time_PE\": 0.049044132232666016,\n",
    "          \"ebit_fraction\": 0.16666666666666666,\n",
    "          ...\n",
    "        }\n",
    "    Groups by (num_qubits, fraction) and computes:\n",
    "        * mean(r_cost), mean(time_r), mean(ebit_fraction)\n",
    "        * lower and upper bound (mean ± std) for each.\n",
    "    Writes these statistics to a .dat file, sorted by fraction first,\n",
    "    and num_qubits second (both ascending).\n",
    "    \"\"\"\n",
    "    # 1. Read the JSON file\n",
    "    with open(input_json_path, 'r') as f:\n",
    "        data = json.load(f)  # Assumes the file is a JSON list of objects\n",
    "    if not os.path.exists(output_dat_path):\n",
    "        os.makedirs(output_dat_path)\n",
    "    # 2. Group the entries by (num_qubits, fraction)\n",
    "    grouped = defaultdict(list)\n",
    "    for entry in data:\n",
    "        key = (entry['num_qubits'], entry['fraction'])\n",
    "        grouped[key].append(entry)\n",
    "    \n",
    "    # 3. Compute statistics\n",
    "    results = []\n",
    "    for (num_qubits, fraction), items in grouped.items():\n",
    "        r_costs = [item['PE_cost'] for item in items]\n",
    "        times = [item['PE_time'] for item in items]\n",
    "        ebits = [item['ebit_fraction'] for item in items]\n",
    "        \n",
    "        # Mean\n",
    "        r_cost_mean = statistics.mean(r_costs)\n",
    "        time_mean = statistics.mean(times)\n",
    "        ebit_mean = statistics.mean(ebits)\n",
    "        \n",
    "        # Standard deviation (use 0 if only 1 item to avoid ValueError)\n",
    "        r_cost_std = statistics.stdev(r_costs) if len(r_costs) > 1 else 0\n",
    "        time_std = statistics.stdev(times) if len(times) > 1 else 0\n",
    "        ebit_std = statistics.stdev(ebits) if len(ebits) > 1 else 0\n",
    "        \n",
    "        # Lower and upper bounds\n",
    "        r_cost_lower, r_cost_upper = r_cost_mean - r_cost_std, r_cost_mean + r_cost_std\n",
    "        time_lower, time_upper = time_mean - time_std, time_mean + time_std\n",
    "        ebit_lower, ebit_upper = ebit_mean - ebit_std, ebit_mean + ebit_std\n",
    "        \n",
    "        results.append(\n",
    "            (\n",
    "                num_qubits, \n",
    "                fraction,\n",
    "                r_cost_mean, r_cost_lower, r_cost_upper,\n",
    "                time_mean, time_lower, time_upper,\n",
    "                ebit_mean, ebit_lower, ebit_upper\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    # 4. Sort the results:\n",
    "    #    * First by fraction ascending\n",
    "    #    * Then by num_qubits ascending\n",
    "    results.sort(key=lambda x: (x[1], x[0]))\n",
    "\n",
    "    # 5. Write statistics to a .dat file\n",
    "    filename = os.path.join(output_dat_path, \"Random_CP_2-12_tket.dat\")\n",
    "    with open(filename, 'w') as out:\n",
    "        # Header\n",
    "        out.write(\"# num_qubits fraction PE_cost_mean PE_cost_lower PE_cost_upper \"\n",
    "                  \"time_PE_mean time_PE_lower time_PE_upper \"\n",
    "                  \"ebit_fraction_mean ebit_fraction_lower ebit_fraction_upper\\n\")\n",
    "        \n",
    "        for row in results:\n",
    "            (nq, frac, \n",
    "             rc_mean, rc_low, rc_up, \n",
    "             t_mean, t_low, t_up, \n",
    "             e_mean, e_low, e_up) = row\n",
    "            out.write(f\"{nq} {frac} \"\n",
    "                      f\"{rc_mean:.6f} {rc_low:.6f} {rc_up:.6f} \"\n",
    "                      f\"{t_mean:.6f} {t_low:.6f} {t_up:.6f} \"\n",
    "                      f\"{e_mean:.6f} {e_low:.6f} {e_up:.6f}\\n\")\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/ftb123/pytket-dqc/examples/benchmark_results_PE_CP_2-12_random.json'\n",
    "\n",
    "output_path = '/Users/ftb123/EEDQC/EECDQC/PGF/CP/Random'\n",
    "\n",
    "create_dat_file_from_json_tket(path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import statistics\n",
    "from collections import defaultdict\n",
    "import os\n",
    "\n",
    "def create_dat_file_from_json(input_json_path: str, output_dat_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Reads a JSON file containing dictionaries of the form:\n",
    "        {\n",
    "          \"num_qubits\": 16,\n",
    "          \"fraction\": 0.3,\n",
    "          \"r_cost\": 7,\n",
    "          \"time_r\": 0.049044132232666016,\n",
    "          \"ebit_fraction\": 0.16666666666666666,\n",
    "          ...\n",
    "        }\n",
    "    Groups by (num_qubits, fraction) and computes:\n",
    "        * mean(r_cost), mean(time_r), mean(ebit_fraction)\n",
    "        * lower and upper bound (mean ± std) for each.\n",
    "    Writes these statistics to a .dat file, sorted by fraction first,\n",
    "    and num_qubits second (both ascending).\n",
    "    \"\"\"\n",
    "    # 1. Read the JSON file\n",
    "    with open(input_json_path, 'r') as f:\n",
    "        data = json.load(f)  # Assumes the file is a JSON list of objects\n",
    "    if not os.path.exists(output_dat_path):\n",
    "        os.makedirs(output_dat_path)\n",
    "    # 2. Group the entries by (num_qubits, fraction)\n",
    "    grouped = defaultdict(list)\n",
    "    for entry in data:\n",
    "        key = (entry['num_qubits'], entry['num_partitions'])\n",
    "        grouped[key].append(entry)\n",
    "    \n",
    "    # 3. Compute statistics\n",
    "    results = []\n",
    "    for (num_qubits, num_partitions), items in grouped.items():\n",
    "        print(num_qubits, num_partitions)\n",
    "        print(items)\n",
    "        r_costs = [item['r_cost'] for item in items]\n",
    "        times = [item['time_r'] for item in items]\n",
    "        \n",
    "        # Mean\n",
    "        r_cost_mean = statistics.mean(r_costs)\n",
    "        time_mean = statistics.mean(times)\n",
    "        \n",
    "        # Standard deviation (use 0 if only 1 item to avoid ValueError)\n",
    "        r_cost_std = statistics.stdev(r_costs) if len(r_costs) > 1 else 0\n",
    "        time_std = statistics.stdev(times) if len(times) > 1 else 0\n",
    "        \n",
    "        # Lower and upper bounds\n",
    "        r_cost_lower, r_cost_upper = r_cost_mean - r_cost_std, r_cost_mean + r_cost_std\n",
    "        time_lower, time_upper = time_mean - time_std, time_mean + time_std\n",
    "        \n",
    "        results.append(\n",
    "            (\n",
    "                num_qubits, \n",
    "                num_partitions,\n",
    "                r_cost_mean, r_cost_lower, r_cost_upper,\n",
    "                time_mean, time_lower, time_upper\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    # 4. Sort the results:\n",
    "    #    * First by fraction ascending\n",
    "    #    * Then by num_qubits ascending\n",
    "    results.sort(key=lambda x: (x[1], x[0]))\n",
    "\n",
    "    # 5. Write statistics to a .dat file\n",
    "    filename = os.path.join(output_dat_path, \"NetCoarse_CP_2-12.dat\")\n",
    "    with open(filename, 'w') as out:\n",
    "        # Header\n",
    "        out.write(\"num_qubits num_partitions r_cost_mean r_cost_lower r_cost_upper \"\n",
    "                  \"time_r_mean time_r_lower time_r_upper \\n\")\n",
    "        \n",
    "        for row in results:\n",
    "            (nq, frac, \n",
    "             rc_mean, rc_low, rc_up, \n",
    "             t_mean, t_low, t_up) = row\n",
    "            out.write(f\"{nq} {frac} \"\n",
    "                      f\"{rc_mean:.6f} {rc_low:.6f} {rc_up:.6f} \"\n",
    "                      f\"{t_mean:.6f} {t_low:.6f} {t_up:.6f} \\n\")\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256 4\n",
      "[{'num_qubits': 256, 'num_partitions': 4, 'iteration': 0, 'r_cost': 7386, 'time_r': 101.07887005805969}]\n",
      "256 16\n",
      "[{'num_qubits': 256, 'num_partitions': 16, 'iteration': 0, 'r_cost': 21647, 'time_r': 692.335987329483}]\n"
     ]
    }
   ],
   "source": [
    "# path = '/Users/ftb123/MLQCP_FM/demos/beta/benchmark_results_MLFM-R_CP_large_netcoarse_linear.json' \n",
    "\n",
    "path = '/Users/ftb123/MLQCP_FM/demos/beta/benchmark_results_MLFM-R_CP_large_comparison_linear.json'\n",
    "\n",
    "output_path = '/Users/ftb123/EEDQC/EECDQC/PGF/CP/NetCoarse/Comparison/'\n",
    "\n",
    "create_dat_file_from_json(path, output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
